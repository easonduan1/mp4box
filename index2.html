<html>

<head>
  <script src="./node_modules/mp4box/dist/mp4box.all.js"></script>
</head>

<body>
  <script>
    var url = "test.mp4";

    var handleAudioEncoding = false;



    var muxStarted = false;

    //---- MP4BOX VARIABLES
    var nbSampleMax = 30; // nb samples extracted each time
    var nbSampleTotal = 0;
    var countSample = 0;
    var file = null;
    var waitingFrame = false;
    var stopped = true;
    var videoTrack = null;
    var audioTrack = null;
    var outputFile = null;
    var oneSecondInMicrosecond = 1000000;

    //---- VIDEO DECODING VARIABLES
    var videoDuration = 0;
    var videoDecoder = null;
    var videoFrames = [];
    var videoNbSample;
    var decodedVideoFrameCount = 0;
    var processingVideo = false;
    var videoFramerate;
    var videoW;
    var videoH;


    //---- AUDIO DECODING VARIABLES
    var audioDecoder = null;
    var audioSampleLength = 1024;
    var audioSamplerate;
    var audioChannelCount;
    var audioNbSample;
    var audioFrames = [];
    var decodedAudioFrameCount = 0;
    var leftChannelOptions = { planeIndex: 0, frameOffset: 0, frameCount: audioSampleLength };
    var rightChannelOptions = { planeIndex: 1, frameOffset: 0, frameCount: audioSampleLength };
    var processingAudio = false;

    //----- VIDEO ENCODER VARIABLES 
    var videoEncoder = null;
    var encodingFrameDistance = 5// difference between last reading frame and last encoding frame
    // |-> we need to slow down the process in order to avoid a saturation of VideoEncoder
    // |==> when VideoEncoder is saturated by the data we send, the process became much more slower
    // |===> so, I'll pause the video decoding/reading when VideoDecoder progression became too late 

    var waitingVideoReading = false;
    var encodedVideoFrameCount = 0;
    var encodingVideoTrack = null;
    var videoFrameDurationInMicrosecond;
    var encodingVideoScale = 0.5; //we will transcode the video in another size ()
    var outputW;
    var outputH;

    //------ AUDIO ENCODING VARIABLES 
    var audioEncoder = null;
    var waitingAudioReading = false;
    var encodingAudioTrack = null;
    var encodedAudioFrameCount = 0;


    var output = document.createElement("canvas");
    output.width = outputW;
    output.height = outputH;
    var ctx = output.getContext("2d");

    document.body.appendChild(output);



    //---- Utility functions  --

    let freeMemory = () => {
      if (processingVideo) {
        if (decodedVideoFrameCount > 0) {
          //let trackId = videoTrack.id;
          //let lastSampleUsed = decodedVideoFrameCount-1;
          file.releaseUsedSamples(videoTrack.id, decodedVideoFrameCount - 1);
        }
        return
      }
      if (processingAudio) {
        if (decodedAudioFrameCount > 0) {
          file.releaseUsedSamples(audioTrack.id, decodedAudioFrameCount - 1);
        }
        return
      }

    }

    let onVideoDemuxingComplete = () => {
      console.log("video demux complete");
      videoDecoder.close();

      processingVideo = false;

      if (audioTrack && handleAudioEncoding) {

        setupAudioEncoder({
          codec: audioTrack.codec,
          sampleRate: audioTrack.audio.sample_rate,
          numberOfChannels: audioTrack.audio.channel_count,
          bitrate: audioTrack.bitrate
        })

        setupAudioDecoder({
          codec: audioTrack.codec,
          sampleRate: audioTrack.audio.sample_rate,
          numberOfChannels: audioTrack.audio.channel_count
        })

        getNextSampleArray();
      }

    }

    let saveFile = () => {
      outputFile.save("test.mp4");
      console.log("file saved !");
    }

    let onAudioDemuxingComplete = () => {
      console.log("onAudioDemuxCompleted !")
      audioDecoder.close();
    }

    let onAudioEncodingComplete = () => {
      audioEncoder.close();
      saveFile();
    }

    let onVideoEncodingComplete = () => {
      console.log("video encoding complete !")
      videoEncoder.close() //<=== in chrome 93 I must add a timeout in order to close the videoEncoder without error (ok in canary) 

      if (!audioTrack || !handleAudioEncoding) saveFile();
    }



    let continueReading = () => {
      if (processingVideo) {
        waitingVideoReading = decodedVideoFrameCount - encodedVideoFrameCount > encodingFrameDistance;

        console.log("VIDEO decodedFrameCount:", decodedVideoFrameCount + " VS encodedFrameCount:" + encodedVideoFrameCount)

        if (waitingVideoReading == false) readNextFrame();
        else console.log("waiting videoEncoder")

        return;
      }

      if (processingAudio) {
        waitingAudioReading = decodedAudioFrameCount - encodedAudioFrameCount > encodingFrameDistance;

        console.log("AUDIO decodedFrameCount:", decodedVideoFrameCount + " VS encodedFrameCount:" + encodedVideoFrameCount)

        if (waitingAudioReading == false) readNextFrame();
        else console.log("waiting audioEncoder")
      }
    }

    let onVideoFrameReadyToUse = (imageBitmap) => {

      createImageBitmap(imageBitmap, 0, 0, videoW, videoH, { resizeWidth: outputW, resizeHeight: outputH, resizeQuality: "high" }).then((bmp) => {
        ctx.drawImage(bmp, 0, 0);

        let timestamp = videoFrameDurationInMicrosecond * decodedVideoFrameCount;
        console.log(timestamp)

        let videoFrame = new VideoFrame(bmp, { timestamp: timestamp });
        videoEncoder.encode(videoFrame);
        videoFrame.close();
        bmp.close();


        decodedVideoFrameCount++;

        if (decodedVideoFrameCount == nbSampleTotal) onVideoDemuxingComplete();
        else continueReading();

      })


      imageBitmap.close();




    }

    let onAudioFrameReadyToUse = (audioFrame) => {

      /*
      //just an example to expose how to get audio-sample-buffers from AudioData object :
      //
      //let leftChannel = new Float32Array(audioSampleLength * 4);
      //audioFrame.copyTo(leftChannel,leftChannelOptions);
      //
      //let rightChannel = leftChannel;
      //if(audioFrame.numberOfChannels > 1){
      //    rightChannel = new Float32Array(audioSampleLength * 4);
      //    audioFrame.copyTo(rightChannel,rightChannelOptions);
      //}

      
      */


      audioEncoder.encode(audioFrame);
      audioFrame.close();

      decodedAudioFrameCount++;

      if (decodedAudioFrameCount == nbSampleTotal) onAudioDemuxingComplete();
      else readNextFrame();
    }


    let getNextSampleArray = () => {
      if (!stopped || !muxStarted || (processingVideo && countSample == nbSampleTotal)) return;

      stopped = false;
      file.start();
    }

    let readNextFrame = () => {

      if (processingVideo) {

        if (videoFrames.length == 0) {
          if (decodedVideoFrameCount > 0) {

            if (!waitingFrame) {
              waitingFrame = true;
              //console.log("call getNextSampleArray ",decodedVideoFrameCount)
              getNextSampleArray();
            }
          }
        } else {


          onVideoFrameReadyToUse(videoFrames.shift());
        }
        return
      }

      //-----------

      if (processingAudio) {
        if (audioFrames.length == 0) {
          if (decodedAudioFrameCount > 0) {
            if (!waitingFrame) {
              waitingFrame = true;
              //console.log("call getNextSampleArray ",decodedAudioFrameCount)
              getNextSampleArray();
            }
          }
        } else {

          onAudioFrameReadyToUse(audioFrames.shift());
        }
        return
      }


    }

    //---- setup videoEncoder -----

    outputFile = MP4Box.createFile();



    let setupVideoEncoder = (config) => {

      let videoEncodingTrackOptions = {
        timescale: oneSecondInMicrosecond,
        w: outputW,
        h: outputH,
        nb_samples: videoNbSample,
        avcDecoderConfigRecord: null
      }

      let videoEncodingSampleOptions = {
        duration: videoFrameDurationInMicrosecond,
        dts: 0,
        cts: 0,
        is_sync: false
      }

      videoEncoder = new window["VideoEncoder"]({
        output: (encodedChunk, config) => {

          if (encodingVideoTrack == null) {
            videoEncodingTrackOptions.avcDecoderConfigRecord = config.decoderConfig.description;
            encodingVideoTrack = outputFile.addTrack(videoEncodingTrackOptions);
          }

          let buffer = new ArrayBuffer(encodedChunk.byteLength);
          encodedChunk.copyTo(buffer);

          videoEncodingSampleOptions.dts = videoEncodingSampleOptions.cts = encodedChunk.timestamp;
          videoEncodingSampleOptions.is_sync = encodedChunk.type == "key";

          outputFile.addSample(encodingVideoTrack, buffer, videoEncodingSampleOptions);

          encodedVideoFrameCount++;

          if (encodedVideoFrameCount == videoNbSample) onVideoEncodingComplete();
          else if (waitingVideoReading) continueReading();




        },
        error: (err) => {
          console.log("VideoEncoder error : ", err);
        }

      });

      videoEncoder.configure(config);


    }

    //--- setup audioEncoder ------

    let setupAudioEncoder = (config) => {

      audioEncoder = new window["AudioEncoder"]({
        output: (encodedChunk, config) => {
          if (config) console.log("AudioEncoder config ", config);
        },
        error: (err) => {
          console.log("AudioEncoder.error : ", err);
        }
      })

      audioEncoder.configure(config);

    }





    //---- setup videoDecoder -----

    let getExtradata = () => {
      // generate the property "description" for the object used in VideoDecoder.configure
      // This function have been written by Thomas Guilbert from Google

      let avccBox = file.moov.traks[0].mdia.minf.stbl.stsd.entries[0].avcC;

      let i, size = 7;
      for (i = 0; i < avccBox.SPS.length; i++) size += 2 + avccBox.SPS[i].length;
      for (i = 0; i < avccBox.PPS.length; i++) size += 2 + avccBox.PPS[i].length;

      let id = 0;
      let data = new Uint8Array(size);

      let writeUint8 = (value) => {
        data.set([value], id);
        id++;
      }
      let writeUint16 = (value) => {
        let arr = new Uint8Array(1);
        arr[0] = value;
        let buffer = new Uint8Array(arr.buffer);
        data.set([buffer[1], buffer[0]], id);
        id += 2;
      }
      let writeUint8Array = (value) => {
        data.set(value, id);
        id += value.length;
      }

      writeUint8(avccBox.configurationVersion);
      writeUint8(avccBox.AVCProfileIndication);
      writeUint8(avccBox.profile_compatibility);
      writeUint8(avccBox.AVCLevelIndication);
      writeUint8(avccBox.lengthSizeMinusOne + (63 << 2));
      writeUint8(avccBox.nb_SPS_nalus + (7 << 5));

      for (i = 0; i < avccBox.SPS.length; i++) {
        writeUint16(avccBox.SPS[i].length);
        writeUint8Array(avccBox.SPS[i].nalu);
      }

      writeUint8(avccBox.nb_PPS_nalus);
      for (i = 0; i < avccBox.PPS.length; i++) {
        writeUint16(avccBox.PPS[i].length);
        writeUint8Array(avccBox.PPS[i].nalu);
      }

      if (id != size) throw "size mismatched !"
      return data;
    }



    let setupVideoDecoder = (config) => {


      let timeout = null;

      processingVideo = true;
      waitingFrame = true;
      countSample = 0;
      nbSampleTotal = videoTrack.nb_samples;

      output.width = outputW;
      output.height = outputH;

      videoDecoder = new window["VideoDecoder"]({
        output: (videoFrame) => {

          createImageBitmap(videoFrame).then((img) => {

            videoFrames.push(img);
            videoFrame.close();
            freeMemory();



            //I use a timeout to give some time to videoDecoder to provide a bunch of frames
            //The idea behind this is to maintain a small amount of active frames in memory. 
            //
            //=> videoDecoder output frame by frame but I can't compare the amount of
            //frame decoded by VideoDecoder and the amount of frame sent to VideoDecoder
            //because the first bunch of frames released by VideoDecoder is always smaller than
            //the amount of frame sent.
            //
            //the amount of frames released at the beginning depends of the video file itself, it's not
            //a fixed value.
            //===> the difference will be released at the end of the decoding using VideoDecoder.flush
            //
            //Without setTimeout, the process start again once I got a single frame.
            //=> I extract new frames once the array "videoFrames" is empty, so if i continue the process
            //immediatly after I got a single frame, the array become empty almost immediatly and the extraction
            //provide a lot of frame too early compared to the real progress of the video-reading

            if (timeout) clearTimeout(timeout);
            timeout = setTimeout(() => {
              if (waitingFrame) {
                waitingFrame = false;
                continueReading();
              }
            }, 15);

          })

          if (!this.started) {
            this.started = true;
            if (this.onReadyToPlay) this.onReadyToPlay();
          }
        },
        error: (e) => {
          console.log("webcodec.VideoDecoder error : ", e);
        }
      })

      videoDecoder.configure(config);
      file.setExtractionOptions(videoTrack.id, null, { nbSamples: nbSampleMax });
    }
    //----- setup AudioDecoder ---------

    let setupAudioDecoder = (config) => {

      let timeout = null;
      countSample = 0;
      processingAudio = true;
      waitingFrame = true;
      nbSampleTotal = audioTrack.nb_samples;
      console.log("audio nb sample total = ", nbSampleTotal)

      audioDecoder = new window["AudioDecoder"]({
        output: (audioFrame) => {
          //console.log("audioFrame = ",audioFrame);



          audioFrames.push(audioFrame);



          if (timeout) clearTimeout(timeout);
          timeout = setTimeout(() => {
            if (waitingFrame) {
              waitingFrame = false;
              readNextFrame();
            }
          }, 15);
        },
        error: (err) => {
          console.log("WebCodec.AudioDecoder error : ", err);
        }
      })

      audioDecoder.configure(config);

      file.setExtractionOptions(audioTrack.id, null, { nbSamples: nbSampleMax });


    }



    //----- setup mp4box and instanciate videoDecoder & videoEncoder ------

    file = MP4Box.createFile();

    file.onerror = (e) => {
      console.log("file onerror ", e);
    }

    file.onError = (e) => {
      console.warn("MP4Box file error => ", e);
    }
    file.onReady = (info) => {
      muxStarted = true;
      videoTrack = info.videoTracks[0];
      audioTrack = info.audioTracks[0];
      console.log("audioTrack ", audioTrack)

      if (audioTrack) {
        audioSamplerate = audioTrack.audio.sample_rate;
        audioChannelCount = audioTrack.audio.channel_count;
        audioNbSample = audioTrack.nb_samples;
      }
      videoNbSample = videoTrack.nb_samples;
      videoDuration = (info.duration / info.timescale) * 1000;
      //|-> with some videos, videoTrack.movie_duration doesn't match with the real duration 

      videoFramerate = Math.ceil(1000 / (videoDuration / videoTrack.nb_samples));
      videoFrameDurationInMicrosecond = oneSecondInMicrosecond / videoFramerate;
      //|-> using Math.ceil doesn't seem to be a good idea, I'll see that later... 

      videoW = videoTrack.track_width;
      videoH = videoTrack.track_height;

      outputW = videoW * encodingVideoScale;
      outputH = videoH * encodingVideoScale;


      console.log("videoFramerate ", videoFramerate)

      setupVideoEncoder({
        codec: 'avc1.42001E',
        width: outputW,
        height: outputH,
        hardwareAcceleration: "prefer-hardware",
        framerate: videoFramerate,
        bitrate: 15000000,
        avc: { format: "avc" }
      })

      setupVideoDecoder({
        codec: videoTrack.codec,
        codedWidth: videoW,
        codedHeight: videoH,
        description: getExtradata()
      })



      onVideoReadyToPlay();
      //=> at the bottom of the code , will call getNextSampleArray();
      //                               |===> will call file.start();
    }


    file.onSamples = (trackId, ref, samples) => {

      //I process the dumux-step little by little in order to save memory 
      //so I stop file reading between 2 demux-process

      if (videoTrack.id == trackId) {
        stopped = true;
        file.stop();


        countSample += samples.length;

        //console.log("onSample ",countSample+" VS "+nbSampleTotal)

        for (const sample of samples) {
          const type = sample.is_sync ? "key" : "delta";

          const chunk = new window["EncodedVideoChunk"]({
            type: type,
            timestamp: sample.cts,
            duration: sample.duration,
            data: sample.data
          });

          videoDecoder.decode(chunk);
        }

        if (countSample == nbSampleTotal) {
          videoDecoder.flush();
        }

        return
      }

      //-----------

      if (audioTrack.id == trackId) {
        //console.log("get audio sample")

        stopped = true;
        file.stop();
        countSample += samples.length;

        //console.log("onSample ",countSample+" VS "+nbSampleTotal)

        for (const sample of samples) {
          const type = sample.is_sync ? "key" : "delta";

          const chunk = new window["EncodedAudioChunk"]({
            type: type,
            timestamp: sample.cts,
            duration: sample.duration,
            data: sample.data,
            offset: sample.offset
          });

          audioDecoder.decode(chunk);
        }

        if (countSample == nbSampleTotal) {
          audioDecoder.flush();
        }
      }



    }


    let loadFile = (url) => {

      fetch(url).then((response) => {
        //we fill our Mp4BoxFile with the data of our video file

        let offset = 0;
        let buf;
        let reader = response.body.getReader();

        let push = () => {
          return reader.read().then(({ done, value }) => {

            if (done == true) {
              file.flush(); //-> will call file.onReady
              return;
            }

            buf = value.buffer;
            buf.fileStart = offset;
            offset += buf.byteLength;
            file.appendBuffer(buf);
            push();
          }).catch((e) => {
            console.log("reader error ", e)
          })

        };
        push();

      })
    }


    //--------------------------



    let onVideoReadyToPlay = () => {
      console.log("videoReadyToPlay")
      getNextSampleArray();
    }

    loadFile(url);


  </script>
  <script>

  </script>
</body>

</html>